{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import gc\n","import torch\n","import argparse\n","import collections\n","import numpy as np\n","import data_loader.data_loaders as module_data\n","from parse_config import ConfigParser\n","import time\n","import shutil\n","from tqdm import *\n","import os\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":401953,"status":"ok","timestamp":1709599142703,"user":{"displayName":"raz ramon","userId":"11363235154750032991"},"user_tz":-120},"id":"jdMsl668LBqk","outputId":"37ab2c3c-7239-407a-b054-1d36d8ca446b"},"outputs":[],"source":["# fix random seeds for reproducibility\n","SEED = 123\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","np.random.seed(SEED)\n","\n","c = \"config/config.json\"\n","p = open(os.path.join(os.path.curdir,c))\n","\n","\n","args_dataset = argparse.ArgumentParser(description='PyTorch Template')\n","args_dataset.add_argument('-c', '--config', default=c, type=str,\n","                    help='config file path (default: None)')\n","args_dataset.add_argument('-r', '--resume', default=None, type=str,\n","                    help='path to latest checkpoint (default: None)')\n","args_dataset.add_argument('-d', '--device', default=None, type=str,\n","                    help='indices of GPUs to enable (default: all)')\n","args_dataset.add_argument('--limited_memory', default=False, action='store_true',\n","                    help='prevent \"too many open files\" error by setting pytorch multiprocessing to \"file_system\".')\n","args_dataset.add_argument(\n","    \"-i\", \"--ip\", help=\"a dummy argument to fool ipython\", default=\"1\")\n","args_dataset.add_argument(\n","    \"-s\", \"--stdin\", help=\"a dummy argument to fool ipython\", default=\"1\")\n","args_dataset.add_argument(\n","    \"-control\", \"--control\", help=\"a dummy argument to fool ipython\", default=\"1\")\n","args_dataset.add_argument(\n","    \"-b\", \"--hb\", help=\"a dummy argument to fool ipython\", default=\"1\")\n","args_dataset.add_argument(\n","    \"-K\", \"--Session.key\", help=\"a dummy argument to fool ipython\", default=\"1\")\n","args_dataset.add_argument(\n","    \"-S\", \"--Session.signature_scheme\", help=\"a dummy argument to fool ipython\", default=\"1\")\n","args_dataset.add_argument(\n","    \"-l\", \"--shell\", help=\"a dummy argument to fool ipython\", default=\"1\")\n","args_dataset.add_argument(\n","    \"-t\", \"--transport\", help=\"a dummy argument to fool ipython\", default=\"1\")\n","args_dataset.add_argument(\n","    \"-o\", \"--iopub\", help=\"a dummy argument to fool ipython\", default=\"1\")\n","args_dataset.add_argument(\n","    \"-f\", \"--ffff\", help=\"a dummy argument to fool ipython\", default=\"1\")\n","# custom cli options to modify configuration from default values given in json file.\n","CustomArgs = collections.namedtuple('CustomArgs', 'flags type target')\n","options = [\n","    CustomArgs(['--lr', '--learning_rate'], type=float, target='optimizer;args;lr'),\n","    CustomArgs(['--bs', '--batch_size'], type=int, target='data_loader;args;batch_size'),\n","    CustomArgs(['--rmb', '--reset_monitor_best'], type=bool, target='trainer;reset_monitor_best'),\n","    CustomArgs(['--vo', '--valid_only'], type=bool, target='trainer;valid_only')\n","]\n","config_dataset = ConfigParser.from_args(args_dataset, options)\n","if args_dataset.parse_args().limited_memory:\n","    # https://github.com/pytorch/pytorch/issues/11201#issuecomment-421146936\n","    import torch.multiprocessing\n","    torch.multiprocessing.set_sharing_strategy('file_system')\n","batch_size = config_dataset.config['data_loader']['args']['batch_size']\n","num_bins = config_dataset.config['data_loader']['args']['sequence_kwargs']['dataset_kwargs']['num_bins']\n","epochs = 50\n","\n","num_files = 0\n","with open(config_dataset.config['data_loader']['args']['data_file']) as f:\n","    num_files = len(f.readlines())\n","\n","seq_size = config_dataset.config['data_loader']['args']['sequence_kwargs']['sequence_length']\n","\n","\n","logger = config_dataset.get_logger('train')\n","\n","# setup data_loader instances\n","train_loader = config_dataset.init_obj('data_loader', module_data)\n","val_loader = config_dataset.init_obj('valid_data_loader', module_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1709599142704,"user":{"displayName":"raz ramon","userId":"11363235154750032991"},"user_tz":-120},"id":"IuX-05sGLBqs","outputId":"22e76f9a-8037-4636-ab9a-0140ff1ccbee"},"outputs":[],"source":["parser = argparse.ArgumentParser(description='Training DCFNet in Pytorch 0.4.0')\n","parser.add_argument('--input_sz', dest='input_sz', default=128, type=int, help='crop input size')\n","parser.add_argument('--padding', dest='padding', default=2.0, type=float, help='crop padding size')\n","parser.add_argument('--range', dest='range', default=10, type=int, help='select range')\n","parser.add_argument('--epochs', default=epochs, type=int, metavar='N',\n","                    help='number of total epochs to run')\n","parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n","                    help='manual epoch number (useful on restarts)')\n","parser.add_argument('--print-freq', '-p', default=10, type=int,\n","                    metavar='N', help='print frequency (default: 10)')\n","parser.add_argument('-j', '--workers', default=0, type=int, metavar='N',\n","                    help='number of data loading workers (default: 8)')\n","parser.add_argument('-b', '--batch-size', default=batch_size, type=int,\n","                    metavar='N', help='mini-batch size (default: 32)')\n","parser.add_argument('--lr', '--learning-rate', default=0.01, type=float,\n","                    metavar='LR', help='initial learning rate')\n","parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n","                    help='momentum')\n","parser.add_argument('--weight-decay', '--wd', default=1e-6, type=float,\n","                    metavar='W', help='weight decay (default: 5e-5)')\n","parser.add_argument('--resume', default='', type=str, metavar='PATH', help='path to latest checkpoint (default: none)')\n","parser.add_argument('--save', '-s', default='./work', type=str, help='directory for saving')\n","parser.add_argument('--num_bins', '-nb', default=num_bins, type=str, help='number of bins')\n","parser.add_argument(\n","    \"-i\", \"--ip\", help=\"a dummy argument to fool ipython\", default=\"1\")\n","parser.add_argument(\n","     \"--stdin\", help=\"a dummy argument to fool ipython\", default=\"1\")\n","parser.add_argument(\n","    \"-control\", \"--control\", help=\"a dummy argument to fool ipython\", default=\"1\")\n","parser.add_argument(\n","    \"--hb\", help=\"a dummy argument to fool ipython\", default=\"1\")\n","parser.add_argument(\n","    \"-K\", \"--Session.key\", help=\"a dummy argument to fool ipython\", default=\"1\")\n","parser.add_argument(\n","    \"-l\", \"--shell\", help=\"a dummy argument to fool ipython\", default=\"1\")\n","parser.add_argument(\n","    \"-t\", \"--transport\", help=\"a dummy argument to fool ipython\", default=\"1\")\n","parser.add_argument(\n","    \"-o\", \"--iopub\", help=\"a dummy argument to fool ipython\", default=\"1\")\n","parser.add_argument(\n","    \"-f\", \"--ffff\", help=\"a dummy argument to fool ipython\", default=\"1\")\n","parser.add_argument(\n","    \"-S\", \"--Session.signature_scheme\", help=\"a dummy argument to fool ipython\", default=\"1\")\n","args = parser.parse_args()\n","\n","print(args)\n","best_loss = 1e6"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":644,"status":"ok","timestamp":1709599143332,"user":{"displayName":"raz ramon","userId":"11363235154750032991"},"user_tz":-120},"id":"92KK4_flLBqt","outputId":"1f2e48e7-d9b6-48c7-9ee6-dd3177cb6e05"},"outputs":[],"source":["\n","def complex_mul(x, z):\n","    out_real = x[..., 0] * z[..., 0] - x[..., 1] * z[..., 1]\n","    out_imag = x[..., 0] * z[..., 1] + x[..., 1] * z[..., 0]\n","    return torch.stack((out_real, out_imag), -1)\n","\n","\n","def complex_mulconj(x, z):\n","    x = torch.view_as_real(x)\n","    z = torch.view_as_real(z)\n","    out_real = x[..., 0] * z[..., 0] + x[..., 1] * z[..., 1]\n","    out_imag = x[..., 1] * z[..., 0] - x[..., 0] * z[..., 1]\n","    return torch.stack((out_real, out_imag), -1)\n","\n","\n","class DCFNetFeature(nn.Module):\n","    def __init__(self,in_channel):\n","        super(DCFNetFeature, self).__init__()\n","        self.feature = nn.Sequential(\n","            nn.Conv2d(in_channel, 32, kernel_size=3),#, padding=1),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(32, 32, 3),\n","            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=1),\n","        )\n","\n","    def forward(self, x):\n","        return self.feature(x)\n","\n","\n","class EventEnc(nn.Module):\n","    def __init__(self,in_channel):\n","        super(EventEnc,self).__init__()\n","        self.conv1 = nn.Conv2d(in_channel, 32, kernel_size=3, stride=1, padding=1)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.relu(x)\n","        x = self.conv2(x)\n","        x = self.pool(x)\n","        return x\n","\n","\n","class GreyEnc(nn.Module):\n","    def __init__(self, in_channel):\n","        super(GreyEnc,self).__init__()\n","        self.conv1 = nn.Conv2d(in_channel, 32, kernel_size=3, stride=1, padding=1)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.relu(x)\n","        x = self.conv2(x)\n","        x = self.pool(x)\n","        return x\n","\n","class Decoder(nn.Module):\n","    def __init__(self):\n","        super(Decoder,self).__init__()\n","        self.convT1 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=1,padding=1)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.convT2 = nn.ConvTranspose2d(32, 32, kernel_size=2, stride=2, padding=1)\n","        self.lclres = nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75, k=1)\n","\n","    def forward(self, x):\n","        x = self.convT1(x)\n","        x = self.relu(x)\n","        x = self.convT2(x)\n","        x = self.lclres(x)\n","        return x\n","\n","\n","class DCFNet(nn.Module):\n","    def __init__(self,in_channel,num_bins, config=None):\n","        super(DCFNet, self).__init__()\n","        self.enc_e = EventEnc(num_bins)\n","        self.enc_f = GreyEnc(in_channel)\n","        self.dec = Decoder()\n","        self.event_feat = DCFNetFeature(num_bins)\n","        self.frame_feat = DCFNetFeature(in_channel)\n","\n","        if(config != None):\n","            self.yf = config.yf.clone()\n","            self.lambda0 = config.lambda0\n","\n","    def forward(self, z, x, label):\n","        zf = torch.torch.fft.rfft2(z)\n","        xf = torch.torch.fft.rfft2(x)\n","\n","        kzzf = torch.sum(torch.sum(torch.view_as_real(zf) ** 2, dim=4, keepdim=True), dim=1, keepdim=True)\n","        kxzf = torch.sum(complex_mulconj(xf, zf), dim=1, keepdim=True)\n","        alphaf = label.to(device=z.device) / (kzzf + self.lambda0)\n","        response = torch.fft.irfft2(torch.view_as_complex(complex_mul(kxzf, alphaf)))\n","        return response\n","\n","def gaussian_shaped_labels(sigma, sz):\n","    x, y = np.meshgrid(np.arange(1, sz[0]+1) - np.floor(float(sz[0]) / 2), np.arange(1, sz[1]+1) - np.floor(float(sz[1]) / 2))\n","    d = x ** 2 + y ** 2\n","    g = np.exp(-0.5 / (sigma ** 2) * d)\n","    g = np.roll(g, int(-np.floor(float(sz[0]) / 2.) + 1), axis=0)\n","    g = np.roll(g, int(-np.floor(float(sz[1]) / 2.) + 1), axis=1)\n","    return g.astype(np.float32)\n","\n","def output_drop(output, target):\n","    delta1 = (output - target)**2\n","    batch_sz = delta1.shape[0]\n","    delta = delta1.view(batch_sz, -1).sum(dim=1)\n","    sort_delta, index = torch.sort(delta, descending=True)\n","    # unreliable samples (10% of the total) do not produce grad (we simply copy the groundtruth label)\n","    for i in range(int(round(0.1*batch_sz))):\n","        output[index[i],...] = target[index[i],...]\n","    return output\n","\n","class TrackerConfig(object):\n","    crop_sz = 128\n","    output_sz = 124\n","    lambda0 = 1e-4\n","    padding = 2.0\n","    output_sigma_factor = 0.1\n","    output_sigma = crop_sz / (1 + padding) * output_sigma_factor\n","    y = gaussian_shaped_labels(output_sigma, [output_sz, output_sz])\n","    yf = torch.fft.rfft2(torch.Tensor(y).view(1, 1, output_sz, output_sz).cuda())\n","    yf = torch.view_as_real(yf)\n","\n","\n","config = TrackerConfig()\n","\n","model = DCFNet(in_channel=num_bins,config=config)\n","model.cuda()\n","gpu_num = torch.cuda.device_count()\n","print('GPU NUM: {:2d}'.format(gpu_num))\n","if gpu_num > 1:\n","    model = torch.nn.DataParallel(model, list(range(gpu_num))).cuda()\n","\n","criterion = nn.MSELoss(size_average=False).cuda()\n","\n","optimizer = torch.optim.SGD(model.parameters(), args.lr,\n","                            momentum=args.momentum,\n","                            weight_decay=args.weight_decay)\n","\n","target = torch.Tensor(config.y).cuda().unsqueeze(0).unsqueeze(0).repeat(args.batch_size * gpu_num, 1, 1, 1)  # for training\n","print(model)\n","dict_net= {}\n","for i,x in enumerate(model.modules()):\n","    dict_net[str(i)] = x\n","\n","args.model = dict_net\n","\n","from datetime import datetime\n","def adjust_learning_rate(optimizer, epoch):\n","    lr = np.logspace(-2, -5, num=args.epochs)[epoch]\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr\n","\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","dt_string = datetime.now().strftime(\"%d%m%Y_%H%M%S\")\n","save_path = os.path.join(args.save, '{}_{:d}_{:1.1f}_{:d}'.format(dt_string,args.input_sz, args.padding,num_bins))\n","if not os.path.isdir(save_path):\n","    os.makedirs(save_path)\n","args.model_path = save_path\n","\n","def save_checkpoint(state, is_best, model_name, filename=os.path.join(save_path, 'checkpoint.pth.tar')):\n","    torch.save(state, filename)\n","    if is_best:\n","        shutil.copyfile(filename, os.path.join(save_path, 'model_best.pth.tar'))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1709599143333,"user":{"displayName":"raz ramon","userId":"11363235154750032991"},"user_tz":-120},"id":"jNe52sONLBqx"},"outputs":[],"source":["def get_features(x, is_frame):\n","    if(is_frame):\n","        x_enc = model.enc_f(x)\n","        x_old = model.frame_feat(x)\n","    else:\n","        x_enc = model.enc_e(x)\n","        x_old = model.event_feat(x)\n","    return model.dec(x_enc) + x_old\n","\n","def get_response(model,template_feat,search1_feat,label,initial_y,args):\n","    with torch.no_grad():\n","        s1_response = model(template_feat, search1_feat, label)\n","    # label transform\n","    peak, index = torch.max(s1_response.view(args.batch_size*gpu_num, -1), 1)\n","    r_max, c_max = np.unravel_index(index.cpu(), [config.output_sz, config.output_sz])\n","    fake_y = np.zeros((args.batch_size*gpu_num, 1, config.output_sz, config.output_sz))\n","    # label shift\n","    for j in range(args.batch_size*gpu_num):\n","        shift_y  = np.roll(initial_y, r_max[j])\n","        fake_y[j,...] = np.roll(shift_y, c_max[j])\n","    fake_yf = torch.fft.rfft2(torch.Tensor(fake_y).view(args.batch_size*gpu_num, 1, config.output_sz, config.output_sz).cuda())\n","    fake_yf = torch.view_as_real(fake_yf)\n","\n","    return fake_yf.cuda(non_blocking=True)\n","\n","def train(train_loader, model, criterion, optimizer, epoch):\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    losses = AverageMeter()\n","\n","    # switch to train mode\n","    model.train()\n","    label = config.yf.repeat(args.batch_size*gpu_num,1,1,1,1).cuda(non_blocking=True)\n","    initial_y = config.y.copy()\n","\n","    end = time.time()\n","\n","    for i, x in enumerate(train_loader):\n","\n","        template = x[0]\n","        search1, search2 = x[1],x[2]\n","\n","        if(template[\"events\"].shape[0] != label.shape[0]):\n","            continue\n","        # measure data loading time\n","        data_time.update(time.time() - end)\n","\n","        template_e = get_features(template[\"events\"].cuda(non_blocking=True),False)\n","        template_f = get_features(template[\"frame\"].cuda(non_blocking=True).permute((0,3,1,2)),True)\n","        template_feat = template_e + template_f\n","\n","        search1_e = get_features(search1[\"events\"].cuda(non_blocking=True),False)\n","        search1_f = get_features(search1[\"frame\"].cuda(non_blocking=True).permute((0,3,1,2)),True)\n","        search1_feat = search1_e + search1_f\n","\n","        search2_e = get_features(search2[\"events\"].cuda(non_blocking=True),False)\n","        search2_f = get_features(search2[\"frame\"].cuda(non_blocking=True).permute((0,3,1,2)),True)\n","        search2_feat = search2_e + search2_f\n","\n","        # forward tracking 1\n","        fake_yf = get_response(model, template_feat, search1_feat, label, initial_y, args)\n","\n","        # forward tracking 2\n","        fake_yf = get_response(model, search1_feat, search2_feat, fake_yf, initial_y, args)\n","\n","        # backward tracking\n","        output = model(search2_feat, template_feat, fake_yf)\n","        output = output_drop(output, target)  # the sample dropout is necessary, otherwise we find the loss tends to become unstable\n","\n","        output_e = model(search2_e, template_e, fake_yf)\n","        output_e = output_drop(output_e, target)\n","\n","        output_f = model(search2_f, template_f, fake_yf)\n","        output_f = output_drop(output_f, target)\n","\n","        # consistency loss. target is the initial Gaussian label\n","        loss = (0.5*criterion(output, target) +0.2*criterion(output_e, target) + 0.3*criterion(output_f, target))/template_feat.size(0)\n","\n","        # measure accuracy and record loss\n","        losses.update(loss.item())\n","\n","        # compute gradient and do SGD step\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","        if(torch.isnan(loss)):\n","            return False\n","\n","        if i % args.print_freq == 0:\n","            print('Epoch: [{0}][{1}/{2}]\\t'\n","                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n","                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n","                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n","                   epoch, i, len(train_loader), batch_time=batch_time,\n","                   data_time=data_time, loss=losses))\n","\n","    return True\n","\n","def validate(val_loader, model, criterion):\n","    batch_time = AverageMeter()\n","    losses = AverageMeter()\n","\n","    model.eval()\n","    initial_y = config.y.copy()\n","    label = config.yf.repeat(args.batch_size*gpu_num,1,1,1,1).cuda(non_blocking=True)\n","\n","    with torch.no_grad():\n","        end = time.time()\n","        for i, x in enumerate(val_loader):\n","\n","            # compute output\n","            template = x[0]\n","            search1, search2 = x[1],x[2]\n","\n","            if(template[\"events\"].shape[0] != label.shape[0]):\n","                continue\n","            template_e = get_features(template[\"events\"].cuda(non_blocking=True),False)\n","            template_f = get_features(template[\"frame\"].cuda(non_blocking=True).permute((0,3,1,2)),True)\n","            template_feat = template_e + template_f\n","\n","            search1_e = get_features(search1[\"events\"].cuda(non_blocking=True),False)\n","            search1_f = get_features(search1[\"frame\"].cuda(non_blocking=True).permute((0,3,1,2)),True)\n","            search1_feat = search1_e + search1_f\n","\n","            search2_e = get_features(search2[\"events\"].cuda(non_blocking=True),False)\n","            search2_f = get_features(search2[\"frame\"].cuda(non_blocking=True).permute((0,3,1,2)),True)\n","            search2_feat = search2_e + search2_f\n","\n","            # forward tracking 1\n","            fake_yf = get_response(model, template_feat, search1_feat, label, initial_y, args)\n","\n","            # forward tracking 2\n","            fake_yf = get_response(model, search1_feat, search2_feat, fake_yf, initial_y, args)\n","\n","            # backward tracking\n","            output = model(search2_feat, template_feat, fake_yf)\n","            output = output_drop(output, target)  # the sample dropout is necessary, otherwise we find the loss tends to become unstable\n","\n","            output_e = model(search2_e, template_e, fake_yf)\n","            output_e = output_drop(output_e, target)\n","\n","            output_f = model(search2_f, template_f, fake_yf)\n","            output_f = output_drop(output_f, target)\n","\n","            # consistency loss. target is the initial Gaussian label\n","            loss = (0.5*criterion(output, target) +0.2*criterion(output_e, target) + 0.3*criterion(output_f, target))/(args.batch_size * gpu_num)\n","\n","            # measure accuracy and record loss\n","            losses.update(loss.item())\n","\n","            # measure elapsed time\n","            batch_time.update(time.time() - end)\n","            end = time.time()\n","\n","            if i % args.print_freq == 0:\n","                print('Test: [{0}/{1}]\\t'\n","                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n","                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n","                       i, len(val_loader), batch_time=batch_time, loss=losses))\n","\n","        print(' * Loss {loss.val:.4f} ({loss.avg:.4f})'.format(loss=losses))\n","\n","    return losses.avg\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["8f1c2c0a524a4830ad3a9020cd229551","dceaee3561454d2eb38be369c149ec95","f2094fde72724f2c98fdd69d63de9da5","bc281981440e42748acb2142ff930ce2","585e3d21b316449187a2e6de3e97c18a","0c55f1a9ce1c40379809a2d85cabd20a","a6af37147beb477fb6d8bdd1b011fdbc","f3f2233ee7f84569a2430a0249bbc447"]},"executionInfo":{"elapsed":13523292,"status":"ok","timestamp":1709612681299,"user":{"displayName":"raz ramon","userId":"11363235154750032991"},"user_tz":-120},"id":"aTOjVQPOLBqz","outputId":"79b8a438-7929-4a53-b93a-646e1692aba9"},"outputs":[],"source":["\n","try:\n","    for epoch in tqdm(range(args.start_epoch, args.epochs)):\n","        adjust_learning_rate(optimizer, epoch)\n","\n","        # train for one epoch\n","        worked = train(train_loader, model, criterion, optimizer, epoch)\n","        if(not worked):\n","            print(\"Broken\")\n","            break\n","        # evaluate on validation set\n","        loss = validate(val_loader, model, criterion)\n","        if(epoch %5 == 0):\n","            print(loss)\n","        # remember best loss and save checkpoint\n","        is_best = loss < best_loss\n","        best_loss = min(best_loss, loss)\n","        save_checkpoint({\n","            'epoch': epoch + 1,\n","            'state_dict': model.state_dict(),\n","            'best_loss': best_loss,\n","            'optimizer': optimizer.state_dict(),\n","        }, is_best,\"baseModel\")\n","\n","except Exception as e:\n","    print(e)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOjZ/jy6CNFdGS2eRFCkRg8","gpuType":"T4","machine_shape":"hm","mount_file_id":"1EAmZrNdSKIm3Jctb-pvlhOgqrXF3DF8h","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"040945ae5a3345ccb2785aa7d94223fe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d7dd2ce6c704cbe9bab8608e8937be9","placeholder":"​","style":"IPY_MODEL_596e0e9f66034ba2b2d0a875d3292b31","value":"16.826 MB of 16.826 MB uploaded\r"}},"0c55f1a9ce1c40379809a2d85cabd20a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0e163d3343c74d52b1bfdd1203aeac29":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2e2809c9cb8f4d018d10c7bf9c1d74b1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55815e8a601f4797a0a0293559a49752":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58423e8050504a00a0dc849b206f7abc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_040945ae5a3345ccb2785aa7d94223fe","IPY_MODEL_5bf167902f3641f498f18da564607544"],"layout":"IPY_MODEL_2e2809c9cb8f4d018d10c7bf9c1d74b1"}},"585e3d21b316449187a2e6de3e97c18a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"596e0e9f66034ba2b2d0a875d3292b31":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5bf167902f3641f498f18da564607544":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_55815e8a601f4797a0a0293559a49752","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0e163d3343c74d52b1bfdd1203aeac29","value":1}},"8d7dd2ce6c704cbe9bab8608e8937be9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f1c2c0a524a4830ad3a9020cd229551":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_dceaee3561454d2eb38be369c149ec95","IPY_MODEL_f2094fde72724f2c98fdd69d63de9da5"],"layout":"IPY_MODEL_bc281981440e42748acb2142ff930ce2"}},"a6af37147beb477fb6d8bdd1b011fdbc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc281981440e42748acb2142ff930ce2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dceaee3561454d2eb38be369c149ec95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_585e3d21b316449187a2e6de3e97c18a","placeholder":"​","style":"IPY_MODEL_0c55f1a9ce1c40379809a2d85cabd20a","value":"56.883 MB of 56.883 MB uploaded\r"}},"f2094fde72724f2c98fdd69d63de9da5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6af37147beb477fb6d8bdd1b011fdbc","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f3f2233ee7f84569a2430a0249bbc447","value":1}},"f3f2233ee7f84569a2430a0249bbc447":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}
